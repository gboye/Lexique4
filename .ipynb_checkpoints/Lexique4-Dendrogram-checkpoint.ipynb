{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul des Dendrogrammes pour Lexique4\n",
    "- modifié pour IMM19 sur Lex3\n",
    "- modifié pour HDR sur Lex4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repHDR=\"/Users/gilles/ownCloud/Recherche/Boye/HDR/Memoire/figs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des résultats de Lexique4-DistributionCoFormes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "import pickle as pkl\n",
    "with open('DendrogramData.pkl',\"rb\") as inFile:  # Python 3: open(..., 'rb')\n",
    "    (Z,clustersLabels,lexemeLabels) = pkl.load(inFile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusterisation des distributions de fréquences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dendrogramLabels(id):\n",
    "    return lexemeLabels[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dendrogramClustersLabels(id):\n",
    "    if id in clustersLabels:\n",
    "        return \", \".join(clustersLabels[id][:5])\n",
    "    else:\n",
    "        return id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusterisation hiérarchique => dendrogramme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.getrecursionlimit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.setrecursionlimit(100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusterisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy as hc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def getLinkage(gParadigme):\n",
    "    data_raw=preparerDataRaw(gParadigme)\n",
    "    data=normaliserDataRaw(data_raw)\n",
    "    Z=hc.linkage(data,method='ward')\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotter le dendrogramme sans troncation\n",
    "Le dendrogramme sans troncation permet d'explorer les voisinages des différents verbes avec les distinctions maximales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDendrogram(Z,parType=\"\",p=None,truncate_mode=None):\n",
    "    plt.figure(figsize=(600,600),)\n",
    "    if truncate_mode:\n",
    "        leaf_label_func=dendrogramClustersLabels\n",
    "        figInsert=u\"-%s-%d-\"%(parType,p)\n",
    "    else:\n",
    "        leaf_label_func=dendrogramLabels\n",
    "        figInsert=u\"-%s-\"%(parType)\n",
    "\n",
    "    dendrogram = hc.dendrogram(Z,\n",
    "                               leaf_label_func=leaf_label_func,\n",
    "                               leaf_font_size=10.,\n",
    "                               p=p,truncate_mode=truncate_mode,\n",
    "                              )\n",
    "    print \"dendrogram\"\n",
    "    plt.savefig(repHDR+u'Lex4-Dendrogram%sVerbes.svg'%figInsert, \n",
    "                dpi=300, \n",
    "                format=\"svg\",\n",
    "                bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération des clusters avec troncation\n",
    "- pour obtenir les clusters, on fait appel à fcluster qui fournit un numéro de cluster pour chaque index de data\n",
    "    - pour obtenir les noms des verbes, on fait la correspondance entre le numéro obtenu et lexemeLabels\n",
    "    - pour obtenir les \"noms\" des clusters, il faut lancer dendrogram une première fois sans plot => R[\"ivl\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lexemeLabels=ixVerbes\n",
    "Z=getLinkage(paradigmeFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbClusters=6000\n",
    "from scipy.cluster.hierarchy import fcluster"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plotDendrogram(Z,parType=u\"Freq\",p=nbClusters,truncate_mode=\"lastp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotDendrogram(Z,parType=u\"Freq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotter les voisins de défectifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plotVoisins(voisins,gParadigme,ylim=None):\n",
    "    for lexeme in voisins:\n",
    "        dfAX=gParadigme[gParadigme[\"lexeme\"]==lexeme].set_index(\"lexeme\")[cases].T\n",
    "        ax=dfAX.plot(kind=\"bar\",\n",
    "                     figsize=(20,5),\n",
    "                     color=sns.color_palette(\"hls\"),\n",
    "                    )\n",
    "        xlabels=ax.get_xticklabels()\n",
    "        for xlabel in xlabels:\n",
    "            xtext=xlabel.get_text()\n",
    "            xlabel.set_backgroundcolor(cellColors[xtext])\n",
    "        if ylim:\n",
    "            ax.set_ylim([0,ylim])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voisins de défectifs (fréquence standard FS, fréquence log FL)\n",
    "- clore\n",
    "    - FS : revisser,(**clore**,(abrutir,promettre))\n",
    "    - FL : (**clore**,(corrompre,méconnaître)),((recoudre,réécrire),(mander,étriper))\n",
    "- distraire\n",
    "    - FS : ((instruire,(séduire,(**distraire**, extraire))),(régénérer,(construire,détruire)))\n",
    "    - FL : (((garantir, investir),(enrichir, rafraîchir)),(blâmer, **distraire**))\n",
    "- abstraire\n",
    "    - FS : ((**abstraire**, pocher),(distancer, proscrire))\n",
    "    - FL : ((**abstraire**, parfaire),(peinturlurer,(civiliser, daller)))\n",
    "- soustraire\n",
    "    - FL : (brutaliser,débrider),(**soustraire**,étayer)\n",
    "- extraire\n",
    "    - FL : (dorloter,désamorcer),(**extraire**,restituer)\n",
    "- retraire, raire\n",
    "    - FL : grêler,(**raire**,**retraire**)\n",
    "- traire\n",
    "    - FL : (**traire**,**frire**),((**clore**,(corrompre,méconnaître)),((recoudre,réécrire),(mander,étriper))\n",
    "    \n",
    "    \n",
    "Il y a aussi quelques vestiges\n",
    "- portraire, attraire\n",
    "    - FS : éclore, crémer, époutier, éperdre, écher, vaser, valeter, troussequiner, tartir, taponner, surglacer, superfinir, sphacéler, sorguer, sniffer, réfranger, réciproquer, redonder, ravoir, ragrandir, raboutir, quérir, pyrrhoniser, pouiller, portraire, méfaire, maquereller, malfaire, mainmettre, galantiser, férir, forpaiser, forfaire, failler, ester, embatre, désoeuvrer, dépatrier, démurger, défâcher, déchouer, couturer, courre, comparoir, chauvir, brouir, bretauder, breller, bouliner, bienvenir, bichoter, bayer, aveindre, attraire, assavoir, argoter, apetisser, alester, alambiquer, aiguayer, accroire, adirer, rassir, occire, reclure, dérayer, rechaper, retordre, regrossir, pionner, coqueter, partouser, hercher, tictaquer, ambler, apponter, jodler, luncher, équeuter, émulsifier, zester, tiller, stripper, soumissionner, signaliser, scolariser, réincarcérer, réargenter, ressemer, resalir, rentamer, rempoter, redémolir, recongeler, reclouer, recarreler, pifer, pastiller, parafer, paginer, inférioriser, hotter, escher, enkyster, enjuiver, encliqueter, embraquer, déventer, désinsectiser, désincruster, désaccoupler, dépoudrer, dénazifier, décriminaliser, déconditionner, décomprimer, dissimiler, diligenter, cureter, coupailler, corréler, contremander, cliver, avitailler, chansonner, quarter, manutentionner, maximiser, exemplifier, trompeter, crosser, maquereauter, syndicaliser, scratcher, rober, rechasser, farter, alcaliniser, alphabétiser, télédiffuser, shampooiner, réabonner, revoter, retuber, reposséder, remprunter, criminaliser, recorder, implémenter, décuver, dépolluer, raller, pleuvioter, varapper, tatillonner, mésuser, lapiner, endêver, dansotter, couchailler, bavocher, bostonner, obvier, rôdailler, égrainer, écornifler, versifier, systématiser, régionaliser, remboîter, reloquer, relaisser, refeuilleter, recogner, reblanchir, rabonnir, pasteuriser, paperasser, maroufler, entrebattre, entr'aimer, engraver, enclouer, encaserner, empanner, désensabler, désenchaîner, désembuer, dépiler, dépaver, démuseler, délustrer, débobiner, correctionnaliser, chabler, cancériser, braser, boyauter, anatomiser, bluter, déconsigner, rapointir, prolétariser, embobeliner, décaisser, désengourdir, mortaiser, vulgariser, décrêper, rebander, désencrasser, rassortir, réséquer, boulanger, réassurer\n",
    "    - FL : éperdre, écher, vaser, valeter, tartir, sniffer, ravoir, quérir, portraire, galantiser, férir, failler, ester, désœuvrer, démurger, déchouer, couturer, courre, comparoir, chauvir, brouir, bayer, attraire, accroire, assavoir\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"voisins de fréquence brute\"\n",
    "plotVoisins(u\"abrutir promettre clore revisser reprendre ensevelir calancher\".split(\" \"),paradigmeFS,ylim=1.2E10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"voisins de fréquence log\"\n",
    "plotVoisins(u\"corrompre méconnaître clore mander étriper recoudre réécrire\".split(\" \"),paradigmeFS,ylim=1.6E9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DISTRAIRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"voisins de fréquence brute\"\n",
    "plotVoisins(u\"instruire séduire distraire extraire régénérer construire détruire\".split(\" \"),paradigmeFS,ylim=2.5E9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"voisins de fréquence log\"\n",
    "plotVoisins(u\"garantir investir enrichir rafraîchir blâmer distraire\".split(\" \"),paradigmeFS,ylim=2.5E9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ABSTRAIRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"voisins de fréquence brute\"\n",
    "plotVoisins(u\"abstraire pocher distancer proscrire\".split(\" \"),paradigmeFS,ylim=10E7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"voisins de fréquence log\"\n",
    "plotVoisins(u\"garantir investir enrichir rafraîchir blâmer distraire\".split(\" \"),paradigmeFS,ylim=2.5E9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lister les défectifs de Boyé(2000) dans les différents clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl in clustersLabels:\n",
    "    print \"cluster\",cl,len(clustersLabels[cl])\n",
    "    print u\"défectifs\",\", \".join([l for l in clustersLabels[cl] if l in boyeDefectifs])\n",
    "    print \"verbes\",\", \".join(clustersLabels[cl])\n",
    "    print\n",
    "#    print \", \".join(clusters[cl])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusterisation par KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choix du nombre de clusters\n",
    "Calcul du WCSS (within cluster sum of squares)\n",
    "kmeans.inertia_ est la valeur du wcss du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "wcss={}\n",
    "for i in range(1,55):\n",
    "    kmeans=KMeans(n_clusters=i,init=\"k-means++\",max_iter=300,n_init=10)\n",
    "    kmeans.fit(data)\n",
    "    wcss[i]=kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWCSS=pd.DataFrame.from_dict(wcss,orient=\"index\")\n",
    "dfWCSS.plot(figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWCSS.diff().plot(figsize=(20,5),xticks=(np.arange(0, 50, step=1))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusterisation autour de K points\n",
    "k-means++ est une stratégie d'initialisation qui permet d'éviter une trappe d'optimisation locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbClusters=7\n",
    "kmeans=KMeans(n_clusters=nbClusters,init=\"k-means++\")\n",
    "y_kmeans=kmeans.fit_predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexemeType={}\n",
    "for nY,y in enumerate(y_kmeans):\n",
    "    lexemeType[lexemeLabels[nY]]=y\n",
    "specialLexemes=boyeDefectifs#[u\"être\",u\"avoir\",u\"pouvoir\",u\"savoir\",u\"faire\"]\n",
    "for lex in specialLexemes:\n",
    "    if lex in lexemeType:\n",
    "        print lex,lexemeType[lex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allLexemes=True\n",
    "typeLexemes = {}\n",
    "for k, v in lexemeType.iteritems():\n",
    "    if k in specialLexemes or allLexemes:\n",
    "        typeLexemes[v] = typeLexemes.get(v, [])\n",
    "        typeLexemes[v].append(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotter les distributions correspondant aux K centres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdKMeans=pd.DataFrame(kmeans.cluster_centers_,columns=cases).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(nbClusters):\n",
    "    iSum=float(pdKMeans[i].sum())\n",
    "#    print iSum\n",
    "    pdKMeans[i]=pdKMeans[i]/iSum\n",
    "#    print pdKMeans[i]\n",
    "    ax=pdKMeans[i].plot(kind=\"bar\",figsize=(10, 3))\n",
    "    ax.set_ylim([0,1])\n",
    "    specLexI=[]\n",
    "    for l in specialLexemes:\n",
    "        if l in typeLexemes[i]:\n",
    "            specLexI.append(l)\n",
    "            if len(specLexI)>=10:\n",
    "                break\n",
    "    nPadLex=5-len(specLexI)\n",
    "    if nPadLex>0:\n",
    "        specLexI=specLexI+typeLexemes[i][:nPadLex]\n",
    "    plt.title(\"Type %d => %d: \"%(i,len(typeLexemes[i]))+\",\".join(specLexI)+u\"\\n\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in typeLexemes:\n",
    "    print element,len(typeLexemes[element]),typeLexemes[element][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfTemp=paradigme[cases].T.isnull().sum()\n",
    "indexFormes1=dfTemp[dfTemp>=45].index.tolist()\n",
    "for ix in indexFormes1:\n",
    "    lexeme=paradigme.iloc[ix][\"lexeme\"]\n",
    "    print lexeme,lexemeType[lexeme]\n",
    "    ax=(paradigme[paradigme[\"lexeme\"]==lexeme].set_index(\"lexeme\")[cases].T.iloc[1:]).plot(kind=\"bar\",figsize=(20,5))\n",
    "    ax.set_ylim([0,1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison des distributions de formes entre des voisins potentiels de CLORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(paradigme[paradigme.lexeme.isin(u\"clore corrompre méconnaître\".split(\" \"))].set_index(\"lexeme\")[cases].T.iloc[1:]).plot(kind=\"bar\",figsize=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(paradigme[paradigme.lexeme.isin(u\"clore abrutir promettre\".split(\" \"))].set_index(\"lexeme\")[cases].T.iloc[1:]).plot(kind=\"bar\",figsize=(20,5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py27)",
   "language": "python",
   "name": "py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
